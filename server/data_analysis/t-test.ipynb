{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import pingouin as pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRIC_ALTERNATIVE_DICT = {\n",
    "    \"Total Time\": \"less\",\n",
    "    \"Consistency\": \"greater\",\n",
    "    \"Cognitive Load\": \"less\",\n",
    "    \"Confidence\": \"greater\",\n",
    "    \"C1\": \"greater\",\n",
    "    \"C1.1\": \"greater\",\n",
    "    \"C1.2\": \"greater\",\n",
    "    \"C1.3\": \"greater\",\n",
    "    \"C2\": \"less\",\n",
    "    \"C2.1\": \"less\",\n",
    "    \"C2.2\": \"greater\",\n",
    "    \"C2.3\": \"greater\",\n",
    "    \"C3.1\": \"greater\",\n",
    "    \"C3.2\": \"less\",\n",
    "    \"C3.3\": \"greater\",\n",
    "    \"C3.4\": \"greater\",\n",
    "    \"C3.5\": \"greater\"\n",
    "}\n",
    "\n",
    "METRIC_COLUMNS = [\n",
    "    \"Total Time\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_df = pd.DataFrame(columns=METRIC_COLUMNS, index=pd.Series([f\"U{i:02d}\" for i in range(1, 42, 2)], name=\"User ID\"))\n",
    "baseline_df.loc[:, METRIC_COLUMNS] = pd.read_csv(\"time_analysis/time/baseline_time_stats.csv\").set_index(\"user\").loc[:, [\"sum\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_df.to_csv(\"time_analysis/baseline.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_df = pd.DataFrame(columns=METRIC_COLUMNS, index=pd.Series([f\"U{i:02d}\" for i in range(2, 43, 2)], name=\"User ID\"))\n",
    "experiment_df.loc[:, METRIC_COLUMNS] = pd.read_csv(\"time_analysis/time/experiment_time_stats.csv\").set_index(\"user\").loc[:, [\"sum\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_df.to_csv(\"time_analysis/experiment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Time\n",
      "\n",
      "normality\n",
      "ShapiroResult(statistic=0.9385712742805481, pvalue=0.20415765047073364)\n",
      "KstestResult(statistic=0.1580516519430466, pvalue=0.6148846234460839, statistic_location=1890.245, statistic_sign=1)\n",
      "ShapiroResult(statistic=0.9131842851638794, pvalue=0.06348296254873276)\n",
      "KstestResult(statistic=0.15453214007436983, pvalue=0.6423118249041351, statistic_location=1087.536, statistic_sign=1)\n",
      "\n",
      "homogeneity of variance\n",
      "LeveneResult(statistic=0.9482251468017145, pvalue=0.33602375683725305)\n",
      "BartlettResult(statistic=2.173988148966523, pvalue=0.1403618076328265)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# t-test assumptions\n",
    "\n",
    "metrics = METRIC_COLUMNS\n",
    "for key in metrics:\n",
    "    sig = False\n",
    "    y = baseline_df.loc[:, key].astype(float).values\n",
    "    x = experiment_df.loc[:, key].astype(float).values\n",
    "    # 1. normality\n",
    "    print()\n",
    "    print(key)\n",
    "    print()\n",
    "    print(\"normality\")\n",
    "    print(stats.shapiro(x))\n",
    "    print(stats.kstest(x, stats.norm(loc=np.mean(x), scale=np.std(x)).cdf))\n",
    "    print(stats.shapiro(y))\n",
    "    print(stats.kstest(y, stats.norm(loc=np.mean(y), scale=np.std(y)).cdf))\n",
    "    print()\n",
    "    # 2. homogeneity of variance\n",
    "    print(\"homogeneity of variance\")\n",
    "    print(stats.levene(x, y))\n",
    "    print(stats.bartlett(x, y))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time                T        dof alternative     p-val          CI95%   cohen-d  \\\n",
      "T-test  3.127275  36.184874        less  0.998263  [-inf, 810.9]  0.965098   \n",
      "\n",
      "         BF10     power  \n",
      "T-test  0.042  0.000001  \n",
      "Total Time                T        dof alternative     p-val          CI95%   cohen-d  \\\n",
      "T-test  3.127275  36.184874     greater  0.001737  [242.36, inf]  0.965098   \n",
      "\n",
      "          BF10     power  \n",
      "T-test  23.716  0.923476  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pearl/miniconda3/envs/robosuite/lib/python3.8/site-packages/scipy/stats/_continuous_distns.py:6826: RuntimeWarning: overflow encountered in _nct_cdf\n",
      "  return np.clip(_boost._nct_cdf(x, df, nc), 0, 1)\n",
      "/Users/pearl/miniconda3/envs/robosuite/lib/python3.8/site-packages/scipy/stats/_continuous_distns.py:6832: RuntimeWarning: overflow encountered in _nct_sf\n",
      "  return np.clip(_boost._nct_sf(x, df, nc), 0, 1)\n"
     ]
    }
   ],
   "source": [
    "result_df = pd.DataFrame(\n",
    "    index=METRIC_COLUMNS,\n",
    "    # T  dof alternative  p-val         CI95%  cohen-d   BF10  power significant\n",
    "    columns=[\n",
    "        \"T\",\n",
    "        \"dof\",\n",
    "        \"alternative\",\n",
    "        \"p-val\",\n",
    "        \"CI95%\",\n",
    "        \"cohen-d\",\n",
    "        \"BF10\",\n",
    "        \"power\",\n",
    "        \"significant\",\n",
    "    ],\n",
    ")\n",
    "metrics = METRIC_COLUMNS\n",
    "for key in metrics:\n",
    "    sig = False\n",
    "    y = baseline_df.loc[:, key].values.tolist()\n",
    "    x = experiment_df.loc[:, key].values.tolist()\n",
    "    result = pg.ttest(\n",
    "        x, y, paired=False, alternative=METRIC_ALTERNATIVE_DICT[key], correction=True\n",
    "    )\n",
    "    sig = result[\"p-val\"].values[0] < 0.05\n",
    "    print(key, result)\n",
    "    result_df.loc[key, :] = result.values[0].tolist() + [sig]\n",
    "    if not sig:\n",
    "        result = pg.ttest(\n",
    "            x,\n",
    "            y,\n",
    "            paired=False,\n",
    "            alternative=\"less\" if METRIC_ALTERNATIVE_DICT[key] == \"greater\" else \"greater\",\n",
    "            correction=True,\n",
    "        )\n",
    "        result_df.loc[key, :] = result.values[0].tolist() + [\n",
    "            result[\"p-val\"].values[0] < 0.05\n",
    "        ]\n",
    "        print(key, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T</th>\n",
       "      <th>dof</th>\n",
       "      <th>alternative</th>\n",
       "      <th>p-val</th>\n",
       "      <th>CI95%</th>\n",
       "      <th>cohen-d</th>\n",
       "      <th>BF10</th>\n",
       "      <th>power</th>\n",
       "      <th>significant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Total Time</th>\n",
       "      <td>3.127275</td>\n",
       "      <td>36.184874</td>\n",
       "      <td>greater</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>[242.36, inf]</td>\n",
       "      <td>0.965098</td>\n",
       "      <td>23.716</td>\n",
       "      <td>0.923476</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   T        dof alternative     p-val          CI95%  \\\n",
       "Total Time  3.127275  36.184874     greater  0.001737  [242.36, inf]   \n",
       "\n",
       "             cohen-d    BF10     power significant  \n",
       "Total Time  0.965098  23.716  0.923476        True  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"result/metric_alternative.json\"):\n",
    "    with open(\"result/metric_alternative.json\", \"r\") as f:\n",
    "        METRIC_ALTERNATIVE_DICT_FILE = json.load(f)\n",
    "if not os.path.exists(\"result/metric_alternative.json\") or METRIC_ALTERNATIVE_DICT != METRIC_ALTERNATIVE_DICT_FILE:\n",
    "    with open(\"result/metric_alternative.json\", \"w\") as f:\n",
    "        json.dump(METRIC_ALTERNATIVE_DICT, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"result/t-test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_result = result_df[result_df['significant'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T</th>\n",
       "      <th>dof</th>\n",
       "      <th>alternative</th>\n",
       "      <th>p-val</th>\n",
       "      <th>CI95%</th>\n",
       "      <th>cohen-d</th>\n",
       "      <th>BF10</th>\n",
       "      <th>power</th>\n",
       "      <th>significant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Total Time</th>\n",
       "      <td>3.127275</td>\n",
       "      <td>36.184874</td>\n",
       "      <td>greater</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>[242.36, inf]</td>\n",
       "      <td>0.965098</td>\n",
       "      <td>23.716</td>\n",
       "      <td>0.923476</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   T        dof alternative     p-val          CI95%  \\\n",
       "Total Time  3.127275  36.184874     greater  0.001737  [242.36, inf]   \n",
       "\n",
       "             cohen-d    BF10     power significant  \n",
       "Total Time  0.965098  23.716  0.923476        True  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robosuite",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
